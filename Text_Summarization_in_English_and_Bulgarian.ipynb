{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Summarization in English and Bulgarian.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPI47xmxGmPRI3Jynec1KwT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnetaKovacheva/text_summarization/blob/main/Text_Summarization_in_English_and_Bulgarian.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text summarization\n",
        "\n",
        "This Notebook explains what text summarization is, and how the extractive approach works. Several examples are provided, both with short and long texts in English and Bulgarian.\n",
        "\n",
        "Text summarization is an NLP task for \"producing a concise and fluent summary while preserving key information and overall meaning\" ([ref](https://towardsdatascience.com/understand-text-summarization-and-create-your-own-summarizer-in-python-b26a9f09fc70)). \n",
        "\n",
        "There are two types of summarization: *abstractive* and *extractive* summarization. Abstractive methods select words based on semantic understanding, even if those words did not appear in the source documents. It aims at producing important material in a new way. They interpret and examine the text using advanced natural language techniques in order to generate a new shorter text that conveys the most critical information from the original text. It can be correlated to the way human reads a text article or blog post and then summarizes in their own word.\n",
        "\n",
        "Extractive methods attempt to summarize articles by selecting a subset of words that retain the most important points. This approach weights the important part of sentences and uses the same to form the summary. Different algorithms and techniques are used to define weights for the sentences and further rank them based on importance and similarity among each other.\n",
        "\n",
        "Abstractive summarization is not well studied yet since it requires a deeper understanding of the text as compared to the extractive approach.\n",
        "\n",
        "Purely extractive summaries often times give better results compared to automatic abstractive summaries. This is because abstractive summarization methods cope with problems such as semantic representation, inference and natural language generation which is relatively harder than data-driven approaches such as sentence extraction ([ref](https://towardsdatascience.com/understand-text-summarization-and-create-your-own-summarizer-in-python-b26a9f09fc70)).\n",
        "\n",
        "When it comes to extractive summarization, it is good to understand the term *Cosine similarity*. It is a measure of similarity between two non-zero vectors of an inner product space that measures the cosine of the angle between them. Since the sentences in the examples below (inspired by [this](https://www.mygreatlearning.com/blog/text-summarization-in-python/) article) will be represented as bunch of vectors, Cosine similarity will be used to find the similarity among sentences. It measures cosine of the angle between vectors. Zero (angle equal to 0) indicates the sentences are similar.\n",
        "\n",
        "I use texts (short and longer) from Deep.AI and *The Guardian* for English texts, and *Mediapool* and *Dnevnik* for texts in Bulgarian, to show how extractive summarization works."
      ],
      "metadata": {
        "id": "RvOaQH4Xy5Rn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "onU5msFs2X7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "from pprint import pprint"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tKFzsG4bj51",
        "outputId": "37aa893b-7a4d-486b-b96c-2757927ac194"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Load texts\n",
        "\n",
        "Shorter texts are directly stored in variables. Longer are loaded from files. Four different text are used in this exercise. \n",
        "\n",
        "The first one (short, in English) explains what Unsupervised Machine Learning is ([source](https://deepai.org/machine-learning-glossary-and-terms/unsupervised-learning\n",
        ")).\n",
        "\n",
        "The second one (long, in English) is an [article](https://www.theguardian.com/environment/2022/aug/20/un-seeks-plan-to-beat-plastic-nurdles-the-tiny-scourges-of-the-oceans\n",
        ") from the Guardian about UN's intention to cope with plastics in the oceans.\n",
        "\n",
        "The third text is from [Mediapool](https://www.mediapool.bg/gartsiya-izliza-ot-nadzora-na-kreditorite-si-news338989.html) (short, in Bulgarian) about Greece's economy and that it no longer will be monitored by its creditors. \n",
        "\n",
        "Finally, the last text is from [Dnevnik](https://www.dnevnik.bg/sviat/2022/08/21/4382081_vuv_velikobritaniia_durvetata_veche_reagirat_vse_edno/?ref=home_NaiNovoto). It is longer and in Bulgarian, and is a story about trees in UK which behaves as it is already an autumn."
      ],
      "metadata": {
        "id": "iSSMnc6Q2piH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_1 = \"Unsupervised learning is a kind of machine learning where a model must look for patterns in a dataset with no labels and with minimal human supervision. This is in contrast to supervised learning techniques, such as classification or regression, where a model is given a training set of inputs and a set of observations, and must learn a mapping from the inputs to the observations. In unsupervised learning, only the inputs are available, and a model must look for interesting patterns in the data. Another name for unsupervised learning is knowledge discovery. Common unsupervised learning techniques include clustering, and dimensionality reduction.\""
      ],
      "metadata": {
        "id": "15Yq8rkZgUEi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "0hau5vXR5Qu-",
        "outputId": "cce5db01-6a00-48d3-8cbf-0fe7d1f7aff5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Unsupervised learning is a kind of machine learning where a model must look for patterns in a dataset with no labels and with minimal human supervision. This is in contrast to supervised learning techniques, such as classification or regression, where a model is given a training set of inputs and a set of observations, and must learn a mapping from the inputs to the observations. In unsupervised learning, only the inputs are available, and a model must look for interesting patterns in the data. Another name for unsupervised learning is knowledge discovery. Common unsupervised learning techniques include clustering, and dimensionality reduction.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"un_beat_plastics.txt\", \"r\") as f:\n",
        "  text_2 = f.read()"
      ],
      "metadata": {
        "id": "I25O0APtiJuV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "BA2Zz3We5NzP",
        "outputId": "b37e93b2-712c-468d-df16-6881cb011361"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Maritime authorities are considering stricter controls on the ocean transport of billions of plastic pellets known as nurdles after a series of spillages around the world. Campaigners warn that nurdles are one of the most common micro-plastic pollutants in the seas, washing up on beaches from New Zealand to Cornwall. The multicoloured pellets produced by petrochemical companies are used as building blocks for plastic products, from bags to bottles and piping. Billions of nurdles washed up in Sri Lanka in May last year after the container ship X-Press Pearl caught fire and sank in the Indian Ocean. The United Nations said the spillage of about 1,680 tonnes of nurdles was the worst maritime disaster in Sri Lanka’s history, with one official saying the spillage was like a “cluster bomb”. The International Maritime Organization, a UN agency, has asked pollution experts to examine the options for “reducing the environmental risk associated with the maritime transport of plastic pellets (nurdles)”. The IMO said a panel of experts would submit their findings for a meeting in April next year. Sri Lanka has called for nurdles transported in container ships to be identified as a harmful substance and a hazard to the marine environment. It would mean tighter procedures to reduce the risk of a spill. In a submission by Sri Lanka to the IMO after the X-Press Pearl sinking, officials said: “The incident has resulted in deaths of marine species such as turtles, whales and dolphins. “There need to be immediate steps taken to regulate and better coordinate the handling, management, and transportation of plastic pellets through the entire supply chain. Voluntary plastic industry initiatives are not sufficient.” '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_3 = \"Гърция излиза от надзора на международните кредитори след повече от десетилетие на ограничения във финансовия сектор. 'Добрите показатели на гръцката икономика и успешните реформи позволяват свалянето на строгия финансов контрол', съобщи финансовият министър Христос Стайкурас, цитиран от БНР.  В следствие на икономическата криза доходите на гърците намаляха с една четвърт, а много хора останаха без работа. Преди това Гърция беше натрупала огромен външен дълг, който дълги години бе прикриван от националната статистка. Финансовата криза от 2009 година обаче оголи всички проблеми и Гърция трябваше да бъде спасявана от фалит. Финансовата дисциплина на страната позволи възстановяването да започне. Експертите посочват, че последните години Гърция е променила икономическия модел и е успяла да привлече инвестиции, за да обслужва кредитите си. Преди това трябваше да бъде проведени болезнени решения като приватизация на редица държавни активи, които предизвикаха масови протести.\""
      ],
      "metadata": {
        "id": "ABb_86-vrQ3h"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "nSo4HKA35U4D",
        "outputId": "53f6c103-407e-4d4f-e263-3f2eae444e4d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Гърция излиза от надзора на международните кредитори след повече от десетилетие на ограничения във финансовия сектор. 'Добрите показатели на гръцката икономика и успешните реформи позволяват свалянето на строгия финансов контрол', съобщи финансовият министър Христос Стайкурас, цитиран от БНР.  В следствие на икономическата криза доходите на гърците намаляха с една четвърт, а много хора останаха без работа. Преди това Гърция беше натрупала огромен външен дълг, който дълги години бе прикриван от националната статистка. Финансовата криза от 2009 година обаче оголи всички проблеми и Гърция трябваше да бъде спасявана от фалит. Финансовата дисциплина на страната позволи възстановяването да започне. Експертите посочват, че последните години Гърция е променила икономическия модел и е успяла да привлече инвестиции, за да обслужва кредитите си. Преди това трябваше да бъде проведени болезнени решения като приватизация на редица държавни активи, които предизвикаха масови протести.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"trees_uk_bg.txt\", \"r\") as f:\n",
        "  text_4 = f.read()"
      ],
      "metadata": {
        "id": "_XaLTOBQwAYX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "e7OpZKlFiRs7",
        "outputId": "687b438b-6fc9-4bc3-8f8e-bcacfb594f7e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Горещата вълна и сушата са тласнали дърветата в обширни части от Великобритания в режим на оцеляване, като листата окапват или променят цвета си в резултат на стрес. Учените наричат това \"фалшива есен\" и предупреждават, че някои дървета може да умрат в резултат на това, съобщи Би Би Си. Кестенявите листа и ранното опадане на листата са признаци, появяващи се при смяната на сезоните Но дните са много по-дълги, отколкото в ранната есен, за да започнат тези естествени есенни процеси. Дърветата реагират така, защото са стресирани, казва Лий Хънт, старши съветник по градинарството в Кралското градинарско дружество. Той казва, че през всичките му 45 години това е една от най-тежките години, които е виждал по отношение на щетите по дърветата в провинцията. Особено са пострадали по-младите дървета без достатъчно дълбока и обширна коренова система, а тези, засадени на бедна почва покрай пътищата, могат да изсъхнат и да умрат. Дърветата, които са загубили само няколко листа с малко пожълтяване, би трябвало да се възстановят с достатъчно валежи, способни да предизвикат \"втора пролет\", обяснява той. Има обаче \"критична точка\", когато дървото не може да попълни водата, изгубена през листата и пред заплахата от изсъхване то започва да пожълтява и да се освобождава от листната маса. Друга извънредна реакция е да произвеждат повече семена - например жълъди и ядки - в опит да се възпроизвеждат и да оцелеят в бъдещето. Резултат на същите процеси е необичайно ранната поява на плодовет по растенията и храстите. Woodland Trust, който регистрира сезонните промени, е получил най-ранното досега съобщение за зрели къпини - от 28 юни. В него се казва, че плодовете и ядките узряват по-бързо от всякога, което \"може да доведе до катастрофа за дивите животни\", които се хранят с тях. Същото се наблюдава при глог, бъз и чемшир. Трудно е да се предскажат дългосрочните последици от сушата, но експертите по екология смятат, че седмици на изсъхнали пасища и твърда като скала почва в голяма част от Южна Англия ще окажат голямо влияние върху дивата природа. В реките и около сушата можеше да се усети години наред. Бързорастящите водорасли могат да задушат останалите растения, блокират светлината. Намаляването на речните нива намалява местообитанията на риби, земноводни и безгръбначни, засягайки цели екосистеми. \"Тези растения осигуряват жизненоважно местообитание за насекоми и риби и загубата им от екосистемата причинява големи промени нагоре по хранителната верига\", казва д-р Майк Боус от Британския център за екология и хидрология. \"Може да отнеме няколко години, преди растенията да успеят да се възстановят или повторно да колонизират тези засегнати от сушата речни участъци и така въздействието на тежките суши може да бъде удължено.\" '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Text preprocessing\n",
        "\n",
        "Text preprocessing invloves removing stop words and tokenization (i.e., split sentences by white space). Stop words are those words that do not bear meaningfull information outside the given context such as i, you, this, that, what, etc. English stop words are encoded in NLTK library but Bulgarian are not yet. For this reason, a list of a stop words in Bulgarian (available [here](https://github.com/stopwords-iso/stopwords-bg/blob/master/stopwords-bg.txt)) is stored in a variable."
      ],
      "metadata": {
        "id": "0cXePgWr58aN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words_bg = {'а', 'автентичен', 'аз', 'ако', 'ала', 'бе', 'без', 'беше', 'бивш', 'бивша', 'бившо', 'бил',\n",
        "    'била', 'били', 'било', 'благодаря', 'близо', 'бъдат', 'бъде', 'бяха', 'в', 'вас', 'ваш', 'ваша', 'вероятно',\n",
        "    'вече', 'взема', 'ви', 'вие', 'винаги', 'внимава', 'време', 'все', 'всеки', 'всички', 'всичко', 'всяка',\n",
        "    'във', 'въпреки', 'върху', 'г', 'ги', 'главен', 'главна', 'главно', 'глас', 'го', 'година', 'години',\n",
        "    'годишен', 'д', 'да', 'дали', 'два', 'двама', 'двамата', 'две', 'двете', 'ден', 'днес', 'дни', 'до', 'добра',\n",
        "    'добре', 'добро', 'добър', 'докато', 'докога', 'дори', 'досега', 'доста', 'друг', 'друга', 'други', 'е',\n",
        "    'евтин', 'едва', 'един', 'една', 'еднаква', 'еднакви', 'еднакъв', 'едно', 'екип', 'ето', 'живот', 'за',\n",
        "    'забавям', 'зад', 'заедно', 'заради', 'засега', 'заспал', 'затова', 'защо', 'защото', 'и', 'из', 'или', 'им',\n",
        "    'има', 'имат', 'иска', 'й', 'каза', 'как', 'каква', 'какво', 'както', 'какъв', 'като', 'кога', 'когато', 'което',\n",
        "    'които', 'кой', 'който', 'колко', 'която', 'къде', 'където', 'към', 'лесен', 'лесно', 'ли', 'лош', 'м', 'май',\n",
        "    'малко', 'ме', 'между', 'мек', 'мен', 'месец', 'ми', 'много', 'мнозина', 'мога', 'могат', 'може', 'мокър', 'моля',\n",
        "    'момента', 'му', 'н', 'на', 'над', 'назад', 'най', 'направи', 'напред', 'например', 'нас', 'не', 'него', 'нещо',\n",
        "    'нея', 'ни', 'ние', 'никой', 'нито', 'нищо', 'но', 'нов', 'нова', 'нови', 'новина', 'някои', 'някой', 'няколко',\n",
        "    'няма', 'обаче', 'около', 'освен', 'особено', 'от', 'отгоре', 'отново', 'още', 'пак', 'по', 'повече', 'повечето',\n",
        "    'под', 'поне', 'поради', 'после', 'почти', 'прави', 'пред', 'преди', 'през', 'при', 'пък', 'първата', 'първи',\n",
        "    'първо', 'пъти', 'равен', 'равна', 'с', 'са', 'сам', 'само', 'се', 'сега', 'си', 'син', 'скоро', 'след', 'следващ',\n",
        "    'сме', 'смях', 'според', 'сред', 'срещу', 'сте', 'съм', 'със', 'също', 'т', 'т.н.', 'тази', 'така', 'такива',\n",
        "    'такъв', 'там', 'твой', 'те', 'тези', 'ти', 'то', 'това', 'тогава', 'този', 'той', 'толкова', 'точно', 'три',\n",
        "    'трябва', 'тук', 'тъй', 'тя', 'тях', 'у', 'утре', 'харесва', 'хиляди', 'ч', 'часа', 'че', 'често', 'чрез', 'ще',\n",
        "    'щом', 'юмрук', 'я', 'як'}"
      ],
      "metadata": {
        "id": "IpJLSHw0krD8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words_en = set(stopwords.words(\"english\"))"
      ],
      "metadata": {
        "id": "UMEF0wJe60Wj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The texts are tokenized by applying the function below."
      ],
      "metadata": {
        "id": "p_bs0TP77IMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_text(text):\n",
        "  \"\"\"\n",
        "  Splits a text into tokens.\n",
        "  Args: Text / strings\n",
        "  Returns tokens\n",
        "  \"\"\"\n",
        "  return word_tokenize(text)"
      ],
      "metadata": {
        "id": "wwWDkT2-68Pc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokeinized texts are stored in variables titled \"words\". One of the splitted texts is shown thereafter."
      ],
      "metadata": {
        "id": "iXbqel9c71_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words_1 = tokenize_text(text_1)\n",
        "words_2 = tokenize_text(text_2)\n",
        "words_3 = tokenize_text(text_3)\n",
        "words_4 = tokenize_text(text_4)\n",
        "print(words_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkr67VHW7VU8",
        "outputId": "48131c38-43e7-4d55-cba2-798b816a494e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Unsupervised', 'learning', 'is', 'a', 'kind', 'of', 'machine', 'learning', 'where', 'a', 'model', 'must', 'look', 'for', 'patterns', 'in', 'a', 'dataset', 'with', 'no', 'labels', 'and', 'with', 'minimal', 'human', 'supervision', '.', 'This', 'is', 'in', 'contrast', 'to', 'supervised', 'learning', 'techniques', ',', 'such', 'as', 'classification', 'or', 'regression', ',', 'where', 'a', 'model', 'is', 'given', 'a', 'training', 'set', 'of', 'inputs', 'and', 'a', 'set', 'of', 'observations', ',', 'and', 'must', 'learn', 'a', 'mapping', 'from', 'the', 'inputs', 'to', 'the', 'observations', '.', 'In', 'unsupervised', 'learning', ',', 'only', 'the', 'inputs', 'are', 'available', ',', 'and', 'a', 'model', 'must', 'look', 'for', 'interesting', 'patterns', 'in', 'the', 'data', '.', 'Another', 'name', 'for', 'unsupervised', 'learning', 'is', 'knowledge', 'discovery', '.', 'Common', 'unsupervised', 'learning', 'techniques', 'include', 'clustering', ',', 'and', 'dimensionality', 'reduction', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shorter texts has around 100 - 150 words, whereas the longer ones between 300 and 500."
      ],
      "metadata": {
        "id": "j2LHG0IA8-Nf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of words in text 1: {len(words_1)}\")\n",
        "print(f\"Number of words in text 2: {len(words_2)}\")\n",
        "print(f\"Number of words in text 3: {len(words_3)}\")\n",
        "print(f\"Number of words in text 4: {len(words_4)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjWgfDhrfsvZ",
        "outputId": "b784622d-4b80-4b54-8b30-f2f0e9b2b68f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in text 1: 112\n",
            "Number of words in text 2: 308\n",
            "Number of words in text 3: 152\n",
            "Number of words in text 4: 491\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Create frequency table\n",
        "\n",
        "The score of each word is kept in a table. It contains information about the number of times each word (outside the stop words list) has appeared in the text. The first function makes the frequency table for English texts, and the second - for the Bulgarian."
      ],
      "metadata": {
        "id": "xDGscbN69ORU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_frequency_table_en(words):\n",
        "  \"\"\"\n",
        "  Creates table with words and their frequency in a tokenized text in English\n",
        "  Args: Tokenized text\n",
        "  Returns the frequency table\n",
        "  \"\"\"\n",
        "  freq_table = dict()\n",
        "\n",
        "  for word in words:\n",
        "    word = word.lower()\n",
        "    if word in stop_words_en:\n",
        "      continue\n",
        "    if word in freq_table:\n",
        "      freq_table[word] +=1\n",
        "    else:\n",
        "      freq_table[word] = 1\n",
        "      \n",
        "  return freq_table"
      ],
      "metadata": {
        "id": "_kE4Mr8h928S"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_frequency_table_bg(words):\n",
        "  \"\"\"\n",
        "  Creates table with words and their frequency in a tokenized text in Bulgarian\n",
        "  Args: Tokenized text\n",
        "  Returns the frequency table\n",
        "  \"\"\"\n",
        "  freq_table = dict()\n",
        "\n",
        "  for word in words:\n",
        "    word = word.lower()\n",
        "    if word in stop_words_bg:\n",
        "      continue\n",
        "    if word in freq_table:\n",
        "      freq_table[word] +=1\n",
        "    else:\n",
        "      freq_table[word] = 1\n",
        "      \n",
        "  return freq_table"
      ],
      "metadata": {
        "id": "i1WpmV6J-Rf-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, frequency tables are compiled for all four tokenized texts."
      ],
      "metadata": {
        "id": "seTjXVY4-4Jr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "freq_table_1 = make_frequency_table_en(words_1)\n",
        "freq_table_2 = make_frequency_table_en(words_2)\n",
        "freq_table_3 = make_frequency_table_bg(words_3)\n",
        "freq_table_4 = make_frequency_table_bg(words_4)"
      ],
      "metadata": {
        "id": "9hwvtQ2__Ddr"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Create dictionary with scores of each sentence and compute values\n",
        "\n",
        "The next step is to compute and track the scores of each sentence. To that end, the whole text is tokenized into sentences. Thereafter, the sentence value is computed based on the number of times a word appears in the sentence in question."
      ],
      "metadata": {
        "id": "j2Di51W7_ha7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_sentence_score(text, freq_table):\n",
        "  \"\"\"\n",
        "  Tokenizes text into sentences and computes sentence score\n",
        "  Args: Text, Frequency table\n",
        "  Returns: tokenized sentences, and dictionary with each sentence score (value)\n",
        "  \"\"\"\n",
        "  sentences = sent_tokenize(text)\n",
        "  sentence_value = dict()\n",
        "\n",
        "  for sentence in sentences:\n",
        "    for word, freq in freq_table.items():\n",
        "      if word in sentence.lower():\n",
        "        if sentence in sentence_value:\n",
        "          sentence_value[sentence] += freq\n",
        "        else:\n",
        "          sentence_value[sentence] = freq\n",
        "\n",
        "  return sentences, sentence_value"
      ],
      "metadata": {
        "id": "0UbilfXZ_0Lf"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentence score is computed for all texts by applying the function above. Scores assigned to the sentences in the first text is displayed below."
      ],
      "metadata": {
        "id": "ZrOL9wemBvjC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_1, sentence_value_1 = compute_sentence_score(text_1, freq_table_1)\n",
        "sentences_2, sentence_value_2 = compute_sentence_score(text_2, freq_table_2)\n",
        "sentences_3, sentence_value_3 = compute_sentence_score(text_3, freq_table_3)\n",
        "sentences_4, sentence_value_4 = compute_sentence_score(text_4, freq_table_4)"
      ],
      "metadata": {
        "id": "uVMu_jH9BRUv"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_value_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10qiCSx9CEz3",
        "outputId": "b8620a15-6668-4f8d-da84-15ffc05ccb65"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Unsupervised learning is a kind of machine learning where a model must look for patterns in a dataset with no labels and with minimal human supervision.': 37,\n",
              " 'This is in contrast to supervised learning techniques, such as classification or regression, where a model is given a training set of inputs and a set of observations, and must learn a mapping from the inputs to the observations.': 40,\n",
              " 'In unsupervised learning, only the inputs are available, and a model must look for interesting patterns in the data.': 39,\n",
              " 'Another name for unsupervised learning is knowledge discovery.': 21,\n",
              " 'Common unsupervised learning techniques include clustering, and dimensionality reduction.': 30}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentence value is used for computing the average value for a sentence. The function below performs these computations."
      ],
      "metadata": {
        "id": "ilsIq3-MDIBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_avg_values(sentence_value):\n",
        "  \"\"\"\n",
        "  Computes the average value (score) for a sentence from the original text\n",
        "  Args: Values of all sentences in a text\n",
        "  Returns: the average value for a sentence.\n",
        "  \"\"\"\n",
        "  sum_values = 0\n",
        "  for sentence in sentence_value:\n",
        "    sum_values += sentence_value[sentence]\n",
        "  \n",
        "  average = int(sum_values / len(sentence_value))\n",
        "\n",
        "  return average"
      ],
      "metadata": {
        "id": "HWJPlfGZALE_"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The averge value is computed for all four texts and is printed thereafter."
      ],
      "metadata": {
        "id": "RPogra6xD789"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg_value_1 = compute_avg_values(sentence_value_1)\n",
        "avg_value_2 = compute_avg_values(sentence_value_2)\n",
        "avg_value_3 = compute_avg_values(sentence_value_3)\n",
        "avg_value_4 = compute_avg_values(sentence_value_4)\n",
        "\n",
        "print(f\"The average value for text 1 is: {avg_value_1}\")\n",
        "print(f\"The average value for text 2 is: {avg_value_2}\")\n",
        "print(f\"The average value for text 3 is: {avg_value_3}\")\n",
        "print(f\"The average value for text 4 is: {avg_value_4}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcOzM0UKC0lS",
        "outputId": "1babc3cc-8189-4e62-dad1-229ac5fb9df1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The average value for text 1 is: 33\n",
            "The average value for text 2 is: 45\n",
            "The average value for text 3 is: 25\n",
            "The average value for text 4 is: 66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Produce text summary\n",
        "\n",
        "Text summary is generated from those existing sentences, whose score is greater than the average value increased by 20%. The function below checks which sentences meet these criteria, and collects them in a variable."
      ],
      "metadata": {
        "id": "ZO77U3t0EWcz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_summarization(sentences, sentence_value, avg_value):\n",
        "  \"\"\"\n",
        "  Computes each sentence score and generates text summarization\n",
        "  Args: sentences: tokenized text into sentences\n",
        "        sentence_value: Sentence score\n",
        "        avg_value: Average value for a sentence\n",
        "  Returns: summarized text\n",
        "  \"\"\"\n",
        "  summary = ''\n",
        "  for sentence in sentences:\n",
        "    if (sentence in sentence_value) and (sentence_value[sentence] > (1.2 * avg_value)):\n",
        "      summary += \" \" + sentence\n",
        "\n",
        "  return summary"
      ],
      "metadata": {
        "id": "IIuZWOxsFQKY"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary_1 = text_summarization(sentences_1, sentence_value_1, avg_value_1)\n",
        "summary_2 = text_summarization(sentences_2, sentence_value_2, avg_value_2)\n",
        "summary_3 = text_summarization(sentences_3, sentence_value_3, avg_value_3)\n",
        "summary_4 = text_summarization(sentences_4, sentence_value_4, avg_value_4)"
      ],
      "metadata": {
        "id": "WeKJ7UytFs-U"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The summarized texts are printed below."
      ],
      "metadata": {
        "id": "WjRvMGz2IaME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "4DTC_IAAr8sX",
        "outputId": "26805442-54e8-4b76-b63d-6dd863ce7df7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' This is in contrast to supervised learning techniques, such as classification or regression, where a model is given a training set of inputs and a set of observations, and must learn a mapping from the inputs to the observations.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "FQKJqx9GISsH",
        "outputId": "8660cb50-3964-425f-8463-7e040d4becdb"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The United Nations said the spillage of about 1,680 tonnes of nurdles was the worst maritime disaster in Sri Lanka’s history, with one official saying the spillage was like a “cluster bomb”. The International Maritime Organization, a UN agency, has asked pollution experts to examine the options for “reducing the environmental risk associated with the maritime transport of plastic pellets (nurdles)”. In a submission by Sri Lanka to the IMO after the X-Press Pearl sinking, officials said: “The incident has resulted in deaths of marine species such as turtles, whales and dolphins.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary_3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "m2dF6snvIX3O",
        "outputId": "c33bcaff-7726-4582-8c48-e048a7d4d4ef"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" 'Добрите показатели на гръцката икономика и успешните реформи позволяват свалянето на строгия финансов контрол', съобщи финансовият министър Христос Стайкурас, цитиран от БНР.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary_4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "VzCjY1U5IjkF",
        "outputId": "2982adaf-9a11-4112-9ca5-599e0974c401"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Горещата вълна и сушата са тласнали дърветата в обширни части от Великобритания в режим на оцеляване, като листата окапват или променят цвета си в резултат на стрес. Трудно е да се предскажат дългосрочните последици от сушата, но експертите по екология смятат, че седмици на изсъхнали пасища и твърда като скала почва в голяма част от Южна Англия ще окажат голямо влияние върху дивата природа. \"Тези растения осигуряват жизненоважно местообитание за насекоми и риби и загубата им от екосистемата причинява големи промени нагоре по хранителната верига\", казва д-р Майк Боус от Британския център за екология и хидрология.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}